# Let's build the GPT Tokenizer

[1. Introduction to Tokenization](1.%20Introduction%20to%20Tokenization)

[2. Naive Tokenization and Its Limitations](2.%20Naive%20Tokenization%20and%20Its%20Limitations)

[3. Character-Level Tokenization](3.%20Character-Level%20Tokenization)

[4. Embedding Table and Token Representation](4.%20Embedding%20Table%20and%20Token%20Representation)

[5. Advanced Tokenization Schemes](5.%20Advanced%20Tokenization%20Schemes)

[6. Byte Pair Encoding Algorithm](6.%20Byte%20Pair%20Encoding%20Algorithm)

[7. Tokenization in GPT-2 Paper](7.%20Tokenization%20in%20GPT-2%20Paper)

[8. Building Our Own Tokenizer](8.%20Building%20Our%20Own%20Tokenizer)

[9. Complexities of Tokenization](9.%20Complexities%20of%20Tokenization)

[10. Live Demonstration of Tokenization](10.%20Live%20Demonstration%20of%20Tokenization)

[11. Tokenization of English Sentences](11.%20Tokenization%20of%20English%20Sentences)

[12. Tokenization of Arithmetic](12.%20Tokenization%20of%20Arithmetic)

[13. Tokenization of Non-English Languages](13.%20Tokenization%20of%20Non-English%20Languages)

[14. Tokenization of Programming Languages](14.%20Tokenization%20of%20Programming%20Languages)

[15. Improvements in GPT-4 Tokenizer](15.%20Improvements%20in%20GPT-4%20Tokenizer)

[16. Writing Tokenization Code](16.%20Writing%20Tokenization%20Code)

[17. Understanding Unicode and UTF-8 Encoding](17.%20Understanding%20Unicode%20and%20UTF-8%20Encoding)

[18. Implementing Byte Pair Encoding](18.%20Implementing%20Byte%20Pair%20Encoding)

[19. Training the Tokenizer](19.%20Training%20the%20Tokenizer)

[20. Encoding and Decoding with the Tokenizer](20.%20Encoding%20and%20Decoding%20with%20the%20Tokenizer)

[21. Special Tokens and Their Usage](21.%20Special%20Tokens%20and%20Their%20Usage)

[22. Tokenization in State-of-the-Art LLMs](22.%20Tokenization%20in%20State-of-the-Art%20LLMs)

[23. Using SentencePiece for Tokenization](23.%20Using%20SentencePiece%20for%20Tokenization)

[24. Recap and Final Thoughts](24.%20Recap%20and%20Final%20Thoughts)